{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { equal } from \"@wry/equality\";\nimport { DeepMerger } from \"../utilities/index.js\";\nimport { mergeIncrementalData } from \"../utilities/index.js\";\nimport { reobserveCacheFirst } from \"./ObservableQuery.js\";\nimport { isNonEmptyArray, graphQLResultHasError, canUseWeakMap } from \"../utilities/index.js\";\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nvar destructiveMethodCounts = new (canUseWeakMap ? WeakMap : Map)();\nfunction wrapDestructiveCacheMethod(cache, methodName) {\n  var original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(cache,\n      // The %1e15 allows the count to wrap around to 0 safely every\n      // quadrillion evictions, so there's no risk of overflow. To be\n      // clear, this is more of a pedantic principle than something\n      // that matters in any conceivable practical scenario.\n      (destructiveMethodCounts.get(cache) + 1) % 1e15);\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\nfunction cancelNotifyTimeout(info) {\n  if (info[\"notifyTimeout\"]) {\n    clearTimeout(info[\"notifyTimeout\"]);\n    info[\"notifyTimeout\"] = void 0;\n  }\n}\n// A QueryInfo object represents a single query managed by the\n// QueryManager, which tracks all QueryInfo objects by queryId in its\n// this.queries Map. QueryInfo objects store the latest results and errors\n// for the given query, and are responsible for reporting those results to\n// the corresponding ObservableQuery, via the QueryInfo.notify method.\n// Results are reported asynchronously whenever setDiff marks the\n// QueryInfo object as dirty, though a call to the QueryManager's\n// broadcastQueries method may trigger the notification before it happens\n// automatically. This class used to be a simple interface type without\n// any field privacy or meaningful methods, which is why it still has so\n// many public fields. The effort to lock down and simplify the QueryInfo\n// interface is ongoing, and further improvements are welcome.\nvar QueryInfo = /** @class */function () {\n  function QueryInfo(queryManager, queryId) {\n    if (queryId === void 0) {\n      queryId = queryManager.generateQueryId();\n    }\n    this.queryId = queryId;\n    this.listeners = new Set();\n    this.document = null;\n    this.lastRequestId = 1;\n    this.stopped = false;\n    this.dirty = false;\n    this.observableQuery = null;\n    var cache = this.cache = queryManager.cache;\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n  QueryInfo.prototype.init = function (query) {\n    var networkStatus = query.networkStatus || NetworkStatus.loading;\n    if (this.variables && this.networkStatus !== NetworkStatus.loading && !equal(this.variables, query.variables)) {\n      networkStatus = NetworkStatus.setVariables;\n    }\n    if (!equal(query.variables, this.variables)) {\n      this.lastDiff = void 0;\n    }\n    Object.assign(this, {\n      document: query.document,\n      variables: query.variables,\n      networkError: null,\n      graphQLErrors: this.graphQLErrors || [],\n      networkStatus: networkStatus\n    });\n    if (query.observableQuery) {\n      this.setObservableQuery(query.observableQuery);\n    }\n    if (query.lastRequestId) {\n      this.lastRequestId = query.lastRequestId;\n    }\n    return this;\n  };\n  QueryInfo.prototype.reset = function () {\n    cancelNotifyTimeout(this);\n    this.dirty = false;\n  };\n  QueryInfo.prototype.resetDiff = function () {\n    this.lastDiff = void 0;\n  };\n  QueryInfo.prototype.getDiff = function () {\n    var options = this.getDiffOptions();\n    if (this.lastDiff && equal(options, this.lastDiff.options)) {\n      return this.lastDiff.diff;\n    }\n    this.updateWatch(this.variables);\n    var oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return {\n        complete: false\n      };\n    }\n    var diff = this.cache.diff(options);\n    this.updateLastDiff(diff, options);\n    return diff;\n  };\n  QueryInfo.prototype.updateLastDiff = function (diff, options) {\n    this.lastDiff = diff ? {\n      diff: diff,\n      options: options || this.getDiffOptions()\n    } : void 0;\n  };\n  QueryInfo.prototype.getDiffOptions = function (variables) {\n    var _a;\n    if (variables === void 0) {\n      variables = this.variables;\n    }\n    return {\n      query: this.document,\n      variables: variables,\n      returnPartialData: true,\n      optimistic: true,\n      canonizeResults: (_a = this.observableQuery) === null || _a === void 0 ? void 0 : _a.options.canonizeResults\n    };\n  };\n  QueryInfo.prototype.setDiff = function (diff) {\n    var _this = this;\n    var _a;\n    var oldDiff = this.lastDiff && this.lastDiff.diff;\n    // If we are trying to deliver an incomplete cache result, we avoid\n    // reporting it if the query has errored, otherwise we let the broadcast try\n    // and repair the partial result by refetching the query. This check avoids\n    // a situation where a query that errors and another succeeds with\n    // overlapping data does not report the partial data result to the errored\n    // query.\n    //\n    // See https://github.com/apollographql/apollo-client/issues/11400 for more\n    // information on this issue.\n    if (diff && !diff.complete && ((_a = this.observableQuery) === null || _a === void 0 ? void 0 : _a.getLastError())) {\n      return;\n    }\n    this.updateLastDiff(diff);\n    if (!this.dirty && !equal(oldDiff && oldDiff.result, diff && diff.result)) {\n      this.dirty = true;\n      if (!this.notifyTimeout) {\n        this.notifyTimeout = setTimeout(function () {\n          return _this.notify();\n        }, 0);\n      }\n    }\n  };\n  QueryInfo.prototype.setObservableQuery = function (oq) {\n    var _this = this;\n    if (oq === this.observableQuery) return;\n    if (this.oqListener) {\n      this.listeners.delete(this.oqListener);\n    }\n    this.observableQuery = oq;\n    if (oq) {\n      oq[\"queryInfo\"] = this;\n      this.listeners.add(this.oqListener = function () {\n        var diff = _this.getDiff();\n        if (diff.fromOptimisticTransaction) {\n          // If this diff came from an optimistic transaction, deliver the\n          // current cache data to the ObservableQuery, but don't perform a\n          // reobservation, since oq.reobserveCacheFirst might make a network\n          // request, and we never want to trigger network requests in the\n          // middle of optimistic updates.\n          oq[\"observe\"]();\n        } else {\n          // Otherwise, make the ObservableQuery \"reobserve\" the latest data\n          // using a temporary fetch policy of \"cache-first\", so complete cache\n          // results have a chance to be delivered without triggering additional\n          // network requests, even when options.fetchPolicy is \"network-only\"\n          // or \"cache-and-network\". All other fetch policies are preserved by\n          // this method, and are handled by calling oq.reobserve(). If this\n          // reobservation is spurious, isDifferentFromLastResult still has a\n          // chance to catch it before delivery to ObservableQuery subscribers.\n          reobserveCacheFirst(oq);\n        }\n      });\n    } else {\n      delete this.oqListener;\n    }\n  };\n  QueryInfo.prototype.notify = function () {\n    var _this = this;\n    cancelNotifyTimeout(this);\n    if (this.shouldNotify()) {\n      this.listeners.forEach(function (listener) {\n        return listener(_this);\n      });\n    }\n    this.dirty = false;\n  };\n  QueryInfo.prototype.shouldNotify = function () {\n    if (!this.dirty || !this.listeners.size) {\n      return false;\n    }\n    if (isNetworkRequestInFlight(this.networkStatus) && this.observableQuery) {\n      var fetchPolicy = this.observableQuery.options.fetchPolicy;\n      if (fetchPolicy !== \"cache-only\" && fetchPolicy !== \"cache-and-network\") {\n        return false;\n      }\n    }\n    return true;\n  };\n  QueryInfo.prototype.stop = function () {\n    if (!this.stopped) {\n      this.stopped = true;\n      // Cancel the pending notify timeout\n      this.reset();\n      this.cancel();\n      // Revert back to the no-op version of cancel inherited from\n      // QueryInfo.prototype.\n      this.cancel = QueryInfo.prototype.cancel;\n      var oq = this.observableQuery;\n      if (oq) oq.stopPolling();\n    }\n  };\n  // This method is a no-op by default, until/unless overridden by the\n  // updateWatch method.\n  QueryInfo.prototype.cancel = function () {};\n  QueryInfo.prototype.updateWatch = function (variables) {\n    var _this = this;\n    if (variables === void 0) {\n      variables = this.variables;\n    }\n    var oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return;\n    }\n    var watchOptions = __assign(__assign({}, this.getDiffOptions(variables)), {\n      watcher: this,\n      callback: function (diff) {\n        return _this.setDiff(diff);\n      }\n    });\n    if (!this.lastWatch || !equal(watchOptions, this.lastWatch)) {\n      this.cancel();\n      this.cancel = this.cache.watch(this.lastWatch = watchOptions);\n    }\n  };\n  QueryInfo.prototype.resetLastWrite = function () {\n    this.lastWrite = void 0;\n  };\n  QueryInfo.prototype.shouldWrite = function (result, variables) {\n    var lastWrite = this.lastWrite;\n    return !(lastWrite &&\n    // If cache.evict has been called since the last time we wrote this\n    // data into the cache, there's a chance writing this result into\n    // the cache will repair what was evicted.\n    lastWrite.dmCount === destructiveMethodCounts.get(this.cache) && equal(variables, lastWrite.variables) && equal(result.data, lastWrite.result.data));\n  };\n  QueryInfo.prototype.markResult = function (result, document, options, cacheWriteBehavior) {\n    var _this = this;\n    var merger = new DeepMerger();\n    var graphQLErrors = isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.reset();\n    if (\"incremental\" in result && isNonEmptyArray(result.incremental)) {\n      var mergedData = mergeIncrementalData(this.getDiff().result, result);\n      result.data = mergedData;\n      // Detect the first chunk of a deferred query and merge it with existing\n      // cache data. This ensures a `cache-first` fetch policy that returns\n      // partial cache data or a `cache-and-network` fetch policy that already\n      // has full data in the cache does not complain when trying to merge the\n      // initial deferred server data with existing cache data.\n    } else if (\"hasNext\" in result && result.hasNext) {\n      var diff = this.getDiff();\n      result.data = merger.merge(diff.result, result.data);\n    }\n    this.graphQLErrors = graphQLErrors;\n    if (options.fetchPolicy === \"no-cache\") {\n      this.updateLastDiff({\n        result: result.data,\n        complete: true\n      }, this.getDiffOptions(options.variables));\n    } else if (cacheWriteBehavior !== 0 /* CacheWriteBehavior.FORBID */) {\n      if (shouldWriteResult(result, options.errorPolicy)) {\n        // Using a transaction here so we have a chance to read the result\n        // back from the cache before the watch callback fires as a result\n        // of writeQuery, so we can store the new diff quietly and ignore\n        // it when we receive it redundantly from the watch callback.\n        this.cache.performTransaction(function (cache) {\n          if (_this.shouldWrite(result, options.variables)) {\n            cache.writeQuery({\n              query: document,\n              data: result.data,\n              variables: options.variables,\n              overwrite: cacheWriteBehavior === 1 /* CacheWriteBehavior.OVERWRITE */\n            });\n            _this.lastWrite = {\n              result: result,\n              variables: options.variables,\n              dmCount: destructiveMethodCounts.get(_this.cache)\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (_this.lastDiff && _this.lastDiff.diff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result.data = _this.lastDiff.diff.result;\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n          var diffOptions = _this.getDiffOptions(options.variables);\n          var diff = cache.diff(diffOptions);\n          // In case the QueryManager stops this QueryInfo before its\n          // results are delivered, it's important to avoid restarting the\n          // cache watch when markResult is called. We also avoid updating\n          // the watch if we are writing a result that doesn't match the current\n          // variables to avoid race conditions from broadcasting the wrong\n          // result.\n          if (!_this.stopped && equal(_this.variables, options.variables)) {\n            // Any time we're about to update this.diff, we need to make\n            // sure we've started watching the cache.\n            _this.updateWatch(options.variables);\n          }\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          _this.updateLastDiff(diff, diffOptions);\n          if (diff.complete) {\n            result.data = diff.result;\n          }\n        });\n      } else {\n        this.lastWrite = void 0;\n      }\n    }\n  };\n  QueryInfo.prototype.markReady = function () {\n    this.networkError = null;\n    return this.networkStatus = NetworkStatus.ready;\n  };\n  QueryInfo.prototype.markError = function (error) {\n    this.networkStatus = NetworkStatus.error;\n    this.lastWrite = void 0;\n    this.reset();\n    if (error.graphQLErrors) {\n      this.graphQLErrors = error.graphQLErrors;\n    }\n    if (error.networkError) {\n      this.networkError = error.networkError;\n    }\n    return error;\n  };\n  return QueryInfo;\n}();\nexport { QueryInfo };\nexport function shouldWriteResult(result, errorPolicy) {\n  if (errorPolicy === void 0) {\n    errorPolicy = \"none\";\n  }\n  var ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  var writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}","map":{"version":3,"names":["equal","DeepMerger","mergeIncrementalData","reobserveCacheFirst","isNonEmptyArray","graphQLResultHasError","canUseWeakMap","NetworkStatus","isNetworkRequestInFlight","destructiveMethodCounts","WeakMap","Map","wrapDestructiveCacheMethod","cache","methodName","original","set","get","apply","arguments","cancelNotifyTimeout","info","clearTimeout","QueryInfo","queryManager","queryId","generateQueryId","listeners","Set","document","lastRequestId","stopped","dirty","observableQuery","has","prototype","init","query","networkStatus","loading","variables","setVariables","lastDiff","Object","assign","networkError","graphQLErrors","setObservableQuery","reset","resetDiff","getDiff","options","getDiffOptions","diff","updateWatch","oq","fetchPolicy","complete","updateLastDiff","returnPartialData","optimistic","canonizeResults","_a","setDiff","_this","oldDiff","getLastError","result","notifyTimeout","setTimeout","notify","oqListener","delete","add","fromOptimisticTransaction","shouldNotify","forEach","listener","size","stop","cancel","stopPolling","watchOptions","__assign","watcher","callback","lastWatch","watch","resetLastWrite","lastWrite","shouldWrite","dmCount","data","markResult","cacheWriteBehavior","merger","errors","slice","incremental","mergedData","hasNext","merge","shouldWriteResult","errorPolicy","performTransaction","writeQuery","overwrite","diffOptions","markReady","ready","markError","error","ignoreErrors","writeWithErrors"],"sources":["C:\\Users\\hp\\Desktop\\banque-service\\banque-service\\banque-frontend\\node_modules\\@apollo\\src\\core\\QueryInfo.ts"],"sourcesContent":["import type { DocumentNode, GraphQLFormattedError } from \"graphql\";\nimport { equal } from \"@wry/equality\";\n\nimport type { Cache, ApolloCache } from \"../cache/index.js\";\nimport { DeepMerger } from \"../utilities/index.js\";\nimport { mergeIncrementalData } from \"../utilities/index.js\";\nimport type { WatchQueryOptions, ErrorPolicy } from \"./watchQueryOptions.js\";\nimport type { ObservableQuery } from \"./ObservableQuery.js\";\nimport { reobserveCacheFirst } from \"./ObservableQuery.js\";\nimport type { QueryListener } from \"./types.js\";\nimport type { FetchResult } from \"../link/core/index.js\";\nimport {\n  isNonEmptyArray,\n  graphQLResultHasError,\n  canUseWeakMap,\n} from \"../utilities/index.js\";\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nimport type { ApolloError } from \"../errors/index.js\";\nimport type { QueryManager } from \"./QueryManager.js\";\n\nexport type QueryStoreValue = Pick<\n  QueryInfo,\n  \"variables\" | \"networkStatus\" | \"networkError\" | \"graphQLErrors\"\n>;\n\nexport const enum CacheWriteBehavior {\n  FORBID,\n  OVERWRITE,\n  MERGE,\n}\n\nconst destructiveMethodCounts = new (canUseWeakMap ? WeakMap : Map)<\n  ApolloCache<any>,\n  number\n>();\n\nfunction wrapDestructiveCacheMethod(\n  cache: ApolloCache<any>,\n  methodName: \"evict\" | \"modify\" | \"reset\"\n) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(\n        cache,\n        // The %1e15 allows the count to wrap around to 0 safely every\n        // quadrillion evictions, so there's no risk of overflow. To be\n        // clear, this is more of a pedantic principle than something\n        // that matters in any conceivable practical scenario.\n        (destructiveMethodCounts.get(cache)! + 1) % 1e15\n      );\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\n\nfunction cancelNotifyTimeout(info: QueryInfo) {\n  if (info[\"notifyTimeout\"]) {\n    clearTimeout(info[\"notifyTimeout\"]);\n    info[\"notifyTimeout\"] = void 0;\n  }\n}\n\n// A QueryInfo object represents a single query managed by the\n// QueryManager, which tracks all QueryInfo objects by queryId in its\n// this.queries Map. QueryInfo objects store the latest results and errors\n// for the given query, and are responsible for reporting those results to\n// the corresponding ObservableQuery, via the QueryInfo.notify method.\n// Results are reported asynchronously whenever setDiff marks the\n// QueryInfo object as dirty, though a call to the QueryManager's\n// broadcastQueries method may trigger the notification before it happens\n// automatically. This class used to be a simple interface type without\n// any field privacy or meaningful methods, which is why it still has so\n// many public fields. The effort to lock down and simplify the QueryInfo\n// interface is ongoing, and further improvements are welcome.\nexport class QueryInfo {\n  listeners = new Set<QueryListener>();\n  document: DocumentNode | null = null;\n  lastRequestId = 1;\n  variables?: Record<string, any>;\n  networkStatus?: NetworkStatus;\n  networkError?: Error | null;\n  graphQLErrors?: ReadonlyArray<GraphQLFormattedError>;\n  stopped = false;\n\n  private cache: ApolloCache<any>;\n\n  constructor(\n    queryManager: QueryManager<any>,\n    public readonly queryId = queryManager.generateQueryId()\n  ) {\n    const cache = (this.cache = queryManager.cache);\n\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n\n  public init(query: {\n    document: DocumentNode;\n    variables: Record<string, any> | undefined;\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus?: NetworkStatus;\n    observableQuery?: ObservableQuery<any, any>;\n    lastRequestId?: number;\n  }): this {\n    let networkStatus = query.networkStatus || NetworkStatus.loading;\n    if (\n      this.variables &&\n      this.networkStatus !== NetworkStatus.loading &&\n      !equal(this.variables, query.variables)\n    ) {\n      networkStatus = NetworkStatus.setVariables;\n    }\n\n    if (!equal(query.variables, this.variables)) {\n      this.lastDiff = void 0;\n    }\n\n    Object.assign(this, {\n      document: query.document,\n      variables: query.variables,\n      networkError: null,\n      graphQLErrors: this.graphQLErrors || [],\n      networkStatus,\n    });\n\n    if (query.observableQuery) {\n      this.setObservableQuery(query.observableQuery);\n    }\n\n    if (query.lastRequestId) {\n      this.lastRequestId = query.lastRequestId;\n    }\n\n    return this;\n  }\n\n  private dirty: boolean = false;\n\n  private notifyTimeout?: ReturnType<typeof setTimeout>;\n\n  reset() {\n    cancelNotifyTimeout(this);\n    this.dirty = false;\n  }\n\n  resetDiff() {\n    this.lastDiff = void 0;\n  }\n\n  getDiff(): Cache.DiffResult<any> {\n    const options = this.getDiffOptions();\n\n    if (this.lastDiff && equal(options, this.lastDiff.options)) {\n      return this.lastDiff.diff;\n    }\n\n    this.updateWatch(this.variables);\n\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return { complete: false };\n    }\n\n    const diff = this.cache.diff(options);\n    this.updateLastDiff(diff, options);\n    return diff;\n  }\n\n  private lastDiff?: {\n    diff: Cache.DiffResult<any>;\n    options: Cache.DiffOptions;\n  };\n\n  private updateLastDiff(\n    diff: Cache.DiffResult<any> | null,\n    options?: Cache.DiffOptions\n  ) {\n    this.lastDiff =\n      diff ?\n        {\n          diff,\n          options: options || this.getDiffOptions(),\n        }\n      : void 0;\n  }\n\n  private getDiffOptions(variables = this.variables): Cache.DiffOptions {\n    return {\n      query: this.document!,\n      variables,\n      returnPartialData: true,\n      optimistic: true,\n      canonizeResults: this.observableQuery?.options.canonizeResults,\n    };\n  }\n\n  setDiff(diff: Cache.DiffResult<any> | null) {\n    const oldDiff = this.lastDiff && this.lastDiff.diff;\n\n    // If we are trying to deliver an incomplete cache result, we avoid\n    // reporting it if the query has errored, otherwise we let the broadcast try\n    // and repair the partial result by refetching the query. This check avoids\n    // a situation where a query that errors and another succeeds with\n    // overlapping data does not report the partial data result to the errored\n    // query.\n    //\n    // See https://github.com/apollographql/apollo-client/issues/11400 for more\n    // information on this issue.\n    if (diff && !diff.complete && this.observableQuery?.getLastError()) {\n      return;\n    }\n\n    this.updateLastDiff(diff);\n\n    if (!this.dirty && !equal(oldDiff && oldDiff.result, diff && diff.result)) {\n      this.dirty = true;\n      if (!this.notifyTimeout) {\n        this.notifyTimeout = setTimeout(() => this.notify(), 0);\n      }\n    }\n  }\n\n  public readonly observableQuery: ObservableQuery<any, any> | null = null;\n  private oqListener?: QueryListener;\n\n  setObservableQuery(oq: ObservableQuery<any, any> | null) {\n    if (oq === this.observableQuery) return;\n\n    if (this.oqListener) {\n      this.listeners.delete(this.oqListener);\n    }\n\n    (this as any).observableQuery = oq;\n\n    if (oq) {\n      oq[\"queryInfo\"] = this;\n      this.listeners.add(\n        (this.oqListener = () => {\n          const diff = this.getDiff();\n          if (diff.fromOptimisticTransaction) {\n            // If this diff came from an optimistic transaction, deliver the\n            // current cache data to the ObservableQuery, but don't perform a\n            // reobservation, since oq.reobserveCacheFirst might make a network\n            // request, and we never want to trigger network requests in the\n            // middle of optimistic updates.\n            oq[\"observe\"]();\n          } else {\n            // Otherwise, make the ObservableQuery \"reobserve\" the latest data\n            // using a temporary fetch policy of \"cache-first\", so complete cache\n            // results have a chance to be delivered without triggering additional\n            // network requests, even when options.fetchPolicy is \"network-only\"\n            // or \"cache-and-network\". All other fetch policies are preserved by\n            // this method, and are handled by calling oq.reobserve(). If this\n            // reobservation is spurious, isDifferentFromLastResult still has a\n            // chance to catch it before delivery to ObservableQuery subscribers.\n            reobserveCacheFirst(oq);\n          }\n        })\n      );\n    } else {\n      delete this.oqListener;\n    }\n  }\n\n  notify() {\n    cancelNotifyTimeout(this);\n\n    if (this.shouldNotify()) {\n      this.listeners.forEach((listener) => listener(this));\n    }\n\n    this.dirty = false;\n  }\n\n  private shouldNotify() {\n    if (!this.dirty || !this.listeners.size) {\n      return false;\n    }\n\n    if (isNetworkRequestInFlight(this.networkStatus) && this.observableQuery) {\n      const { fetchPolicy } = this.observableQuery.options;\n      if (fetchPolicy !== \"cache-only\" && fetchPolicy !== \"cache-and-network\") {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  public stop() {\n    if (!this.stopped) {\n      this.stopped = true;\n\n      // Cancel the pending notify timeout\n      this.reset();\n\n      this.cancel();\n      // Revert back to the no-op version of cancel inherited from\n      // QueryInfo.prototype.\n      this.cancel = QueryInfo.prototype.cancel;\n\n      const oq = this.observableQuery;\n      if (oq) oq.stopPolling();\n    }\n  }\n\n  // This method is a no-op by default, until/unless overridden by the\n  // updateWatch method.\n  private cancel() {}\n\n  private lastWatch?: Cache.WatchOptions;\n\n  private updateWatch(variables = this.variables) {\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return;\n    }\n\n    const watchOptions: Cache.WatchOptions = {\n      // Although this.getDiffOptions returns Cache.DiffOptions instead of\n      // Cache.WatchOptions, all the overlapping options should be the same, so\n      // we can reuse getDiffOptions here, for consistency.\n      ...this.getDiffOptions(variables),\n      watcher: this,\n      callback: (diff) => this.setDiff(diff),\n    };\n\n    if (!this.lastWatch || !equal(watchOptions, this.lastWatch)) {\n      this.cancel();\n      this.cancel = this.cache.watch((this.lastWatch = watchOptions));\n    }\n  }\n\n  private lastWrite?: {\n    result: FetchResult<any>;\n    variables: WatchQueryOptions[\"variables\"];\n    dmCount: number | undefined;\n  };\n\n  public resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n\n  private shouldWrite(\n    result: FetchResult<any>,\n    variables: WatchQueryOptions[\"variables\"]\n  ) {\n    const { lastWrite } = this;\n    return !(\n      lastWrite &&\n      // If cache.evict has been called since the last time we wrote this\n      // data into the cache, there's a chance writing this result into\n      // the cache will repair what was evicted.\n      lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n      equal(variables, lastWrite.variables) &&\n      equal(result.data, lastWrite.result.data)\n    );\n  }\n\n  public markResult<T>(\n    result: FetchResult<T>,\n    document: DocumentNode,\n    options: Pick<\n      WatchQueryOptions,\n      \"variables\" | \"fetchPolicy\" | \"errorPolicy\"\n    >,\n    cacheWriteBehavior: CacheWriteBehavior\n  ) {\n    const merger = new DeepMerger();\n    const graphQLErrors =\n      isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.reset();\n\n    if (\"incremental\" in result && isNonEmptyArray(result.incremental)) {\n      const mergedData = mergeIncrementalData(this.getDiff().result, result);\n      result.data = mergedData;\n\n      // Detect the first chunk of a deferred query and merge it with existing\n      // cache data. This ensures a `cache-first` fetch policy that returns\n      // partial cache data or a `cache-and-network` fetch policy that already\n      // has full data in the cache does not complain when trying to merge the\n      // initial deferred server data with existing cache data.\n    } else if (\"hasNext\" in result && result.hasNext) {\n      const diff = this.getDiff();\n      result.data = merger.merge(diff.result, result.data);\n    }\n\n    this.graphQLErrors = graphQLErrors;\n\n    if (options.fetchPolicy === \"no-cache\") {\n      this.updateLastDiff(\n        { result: result.data, complete: true },\n        this.getDiffOptions(options.variables)\n      );\n    } else if (cacheWriteBehavior !== CacheWriteBehavior.FORBID) {\n      if (shouldWriteResult(result, options.errorPolicy)) {\n        // Using a transaction here so we have a chance to read the result\n        // back from the cache before the watch callback fires as a result\n        // of writeQuery, so we can store the new diff quietly and ignore\n        // it when we receive it redundantly from the watch callback.\n        this.cache.performTransaction((cache) => {\n          if (this.shouldWrite(result, options.variables)) {\n            cache.writeQuery({\n              query: document,\n              data: result.data as T,\n              variables: options.variables,\n              overwrite: cacheWriteBehavior === CacheWriteBehavior.OVERWRITE,\n            });\n\n            this.lastWrite = {\n              result,\n              variables: options.variables,\n              dmCount: destructiveMethodCounts.get(this.cache),\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (this.lastDiff && this.lastDiff.diff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result.data = this.lastDiff.diff.result;\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n\n          const diffOptions = this.getDiffOptions(options.variables);\n          const diff = cache.diff<T>(diffOptions);\n\n          // In case the QueryManager stops this QueryInfo before its\n          // results are delivered, it's important to avoid restarting the\n          // cache watch when markResult is called. We also avoid updating\n          // the watch if we are writing a result that doesn't match the current\n          // variables to avoid race conditions from broadcasting the wrong\n          // result.\n          if (!this.stopped && equal(this.variables, options.variables)) {\n            // Any time we're about to update this.diff, we need to make\n            // sure we've started watching the cache.\n            this.updateWatch(options.variables);\n          }\n\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          this.updateLastDiff(diff, diffOptions);\n          if (diff.complete) {\n            result.data = diff.result;\n          }\n        });\n      } else {\n        this.lastWrite = void 0;\n      }\n    }\n  }\n\n  public markReady() {\n    this.networkError = null;\n    return (this.networkStatus = NetworkStatus.ready);\n  }\n\n  public markError(error: ApolloError) {\n    this.networkStatus = NetworkStatus.error;\n    this.lastWrite = void 0;\n\n    this.reset();\n\n    if (error.graphQLErrors) {\n      this.graphQLErrors = error.graphQLErrors;\n    }\n\n    if (error.networkError) {\n      this.networkError = error.networkError;\n    }\n\n    return error;\n  }\n}\n\nexport function shouldWriteResult<T>(\n  result: FetchResult<T>,\n  errorPolicy: ErrorPolicy = \"none\"\n) {\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}\n"],"mappings":";AACA,SAASA,KAAK,QAAQ,eAAe;AAGrC,SAASC,UAAU,QAAQ,uBAAuB;AAClD,SAASC,oBAAoB,QAAQ,uBAAuB;AAG5D,SAASC,mBAAmB,QAAQ,sBAAsB;AAG1D,SACEC,eAAe,EACfC,qBAAqB,EACrBC,aAAa,QACR,uBAAuB;AAC9B,SAASC,aAAa,EAAEC,wBAAwB,QAAQ,oBAAoB;AAe5E,IAAMC,uBAAuB,GAAG,KAAKH,aAAa,GAAGI,OAAO,GAAGC,GAAG,EAAC,CAGhE;AAEH,SAASC,0BAA0BA,CACjCC,KAAuB,EACvBC,UAAwC;EAExC,IAAMC,QAAQ,GAAGF,KAAK,CAACC,UAAU,CAAC;EAClC,IAAI,OAAOC,QAAQ,KAAK,UAAU,EAAE;IAClC;IACAF,KAAK,CAACC,UAAU,CAAC,GAAG;MAClBL,uBAAuB,CAACO,GAAG,CACzBH,KAAK;MACL;MACA;MACA;MACA;MACA,CAACJ,uBAAuB,CAACQ,GAAG,CAACJ,KAAK,CAAE,GAAG,CAAC,IAAI,IAAI,CACjD;MACD;MACA,OAAOE,QAAQ,CAACG,KAAK,CAAC,IAAI,EAAEC,SAAS,CAAC;IACxC,CAAC;EACH;AACF;AAEA,SAASC,mBAAmBA,CAACC,IAAe;EAC1C,IAAIA,IAAI,CAAC,eAAe,CAAC,EAAE;IACzBC,YAAY,CAACD,IAAI,CAAC,eAAe,CAAC,CAAC;IACnCA,IAAI,CAAC,eAAe,CAAC,GAAG,KAAK,CAAC;EAChC;AACF;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAAE,SAAA;EAYE,SAAAA,UACEC,YAA+B,EACfC,OAAwC;IAAxC,IAAAA,OAAA;MAAAA,OAAA,GAAUD,YAAY,CAACE,eAAe,EAAE;IAAA;IAAxC,KAAAD,OAAO,GAAPA,OAAO;IAbzB,KAAAE,SAAS,GAAG,IAAIC,GAAG,EAAiB;IACpC,KAAAC,QAAQ,GAAwB,IAAI;IACpC,KAAAC,aAAa,GAAG,CAAC;IAKjB,KAAAC,OAAO,GAAG,KAAK;IAiEP,KAAAC,KAAK,GAAY,KAAK;IAsFd,KAAAC,eAAe,GAAqC,IAAI;IA/ItE,IAAMpB,KAAK,GAAI,IAAI,CAACA,KAAK,GAAGW,YAAY,CAACX,KAAM;IAE/C;IACA;IACA;IACA;IACA;IACA,IAAI,CAACJ,uBAAuB,CAACyB,GAAG,CAACrB,KAAK,CAAC,EAAE;MACvCJ,uBAAuB,CAACO,GAAG,CAACH,KAAK,EAAE,CAAC,CAAC;MACrCD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;MAC1CD,0BAA0B,CAACC,KAAK,EAAE,QAAQ,CAAC;MAC3CD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;IAC5C;EACF;EAEOU,SAAA,CAAAY,SAAA,CAAAC,IAAI,GAAX,UAAYC,KASX;IACC,IAAIC,aAAa,GAAGD,KAAK,CAACC,aAAa,IAAI/B,aAAa,CAACgC,OAAO;IAChE,IACE,IAAI,CAACC,SAAS,IACd,IAAI,CAACF,aAAa,KAAK/B,aAAa,CAACgC,OAAO,IAC5C,CAACvC,KAAK,CAAC,IAAI,CAACwC,SAAS,EAAEH,KAAK,CAACG,SAAS,CAAC,EACvC;MACAF,aAAa,GAAG/B,aAAa,CAACkC,YAAY;IAC5C;IAEA,IAAI,CAACzC,KAAK,CAACqC,KAAK,CAACG,SAAS,EAAE,IAAI,CAACA,SAAS,CAAC,EAAE;MAC3C,IAAI,CAACE,QAAQ,GAAG,KAAK,CAAC;IACxB;IAEAC,MAAM,CAACC,MAAM,CAAC,IAAI,EAAE;MAClBf,QAAQ,EAAEQ,KAAK,CAACR,QAAQ;MACxBW,SAAS,EAAEH,KAAK,CAACG,SAAS;MAC1BK,YAAY,EAAE,IAAI;MAClBC,aAAa,EAAE,IAAI,CAACA,aAAa,IAAI,EAAE;MACvCR,aAAa,EAAAA;KACd,CAAC;IAEF,IAAID,KAAK,CAACJ,eAAe,EAAE;MACzB,IAAI,CAACc,kBAAkB,CAACV,KAAK,CAACJ,eAAe,CAAC;IAChD;IAEA,IAAII,KAAK,CAACP,aAAa,EAAE;MACvB,IAAI,CAACA,aAAa,GAAGO,KAAK,CAACP,aAAa;IAC1C;IAEA,OAAO,IAAI;EACb,CAAC;EAMDP,SAAA,CAAAY,SAAA,CAAAa,KAAK,GAAL;IACE5B,mBAAmB,CAAC,IAAI,CAAC;IACzB,IAAI,CAACY,KAAK,GAAG,KAAK;EACpB,CAAC;EAEDT,SAAA,CAAAY,SAAA,CAAAc,SAAS,GAAT;IACE,IAAI,CAACP,QAAQ,GAAG,KAAK,CAAC;EACxB,CAAC;EAEDnB,SAAA,CAAAY,SAAA,CAAAe,OAAO,GAAP;IACE,IAAMC,OAAO,GAAG,IAAI,CAACC,cAAc,EAAE;IAErC,IAAI,IAAI,CAACV,QAAQ,IAAI1C,KAAK,CAACmD,OAAO,EAAE,IAAI,CAACT,QAAQ,CAACS,OAAO,CAAC,EAAE;MAC1D,OAAO,IAAI,CAACT,QAAQ,CAACW,IAAI;IAC3B;IAEA,IAAI,CAACC,WAAW,CAAC,IAAI,CAACd,SAAS,CAAC;IAEhC,IAAMe,EAAE,GAAG,IAAI,CAACtB,eAAe;IAC/B,IAAIsB,EAAE,IAAIA,EAAE,CAACJ,OAAO,CAACK,WAAW,KAAK,UAAU,EAAE;MAC/C,OAAO;QAAEC,QAAQ,EAAE;MAAK,CAAE;IAC5B;IAEA,IAAMJ,IAAI,GAAG,IAAI,CAACxC,KAAK,CAACwC,IAAI,CAACF,OAAO,CAAC;IACrC,IAAI,CAACO,cAAc,CAACL,IAAI,EAAEF,OAAO,CAAC;IAClC,OAAOE,IAAI;EACb,CAAC;EAOO9B,SAAA,CAAAY,SAAA,CAAAuB,cAAc,GAAtB,UACEL,IAAkC,EAClCF,OAA2B;IAE3B,IAAI,CAACT,QAAQ,GACXW,IAAI,GACF;MACEA,IAAI,EAAAA,IAAA;MACJF,OAAO,EAAEA,OAAO,IAAI,IAAI,CAACC,cAAc;KACxC,GACD,KAAK,CAAC;EACZ,CAAC;EAEO7B,SAAA,CAAAY,SAAA,CAAAiB,cAAc,GAAtB,UAAuBZ,SAA0B;;IAA1B,IAAAA,SAAA;MAAAA,SAAA,GAAY,IAAI,CAACA,SAAS;IAAA;IAC/C,OAAO;MACLH,KAAK,EAAE,IAAI,CAACR,QAAS;MACrBW,SAAS,EAAAA,SAAA;MACTmB,iBAAiB,EAAE,IAAI;MACvBC,UAAU,EAAE,IAAI;MAChBC,eAAe,EAAE,CAAAC,EAAA,OAAI,CAAC7B,eAAe,cAAA6B,EAAA,uBAAAA,EAAA,CAAEX,OAAO,CAACU;KAChD;EACH,CAAC;EAEDtC,SAAA,CAAAY,SAAA,CAAA4B,OAAO,GAAP,UAAQV,IAAkC;IAA1C,IAAAW,KAAA;;IACE,IAAMC,OAAO,GAAG,IAAI,CAACvB,QAAQ,IAAI,IAAI,CAACA,QAAQ,CAACW,IAAI;IAEnD;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,IAAIA,IAAI,IAAI,CAACA,IAAI,CAACI,QAAQ,KAAI,CAAAK,EAAA,OAAI,CAAC7B,eAAe,cAAA6B,EAAA,uBAAAA,EAAA,CAAEI,YAAY,EAAE,GAAE;MAClE;IACF;IAEA,IAAI,CAACR,cAAc,CAACL,IAAI,CAAC;IAEzB,IAAI,CAAC,IAAI,CAACrB,KAAK,IAAI,CAAChC,KAAK,CAACiE,OAAO,IAAIA,OAAO,CAACE,MAAM,EAAEd,IAAI,IAAIA,IAAI,CAACc,MAAM,CAAC,EAAE;MACzE,IAAI,CAACnC,KAAK,GAAG,IAAI;MACjB,IAAI,CAAC,IAAI,CAACoC,aAAa,EAAE;QACvB,IAAI,CAACA,aAAa,GAAGC,UAAU,CAAC;UAAM,OAAAL,KAAI,CAACM,MAAM,EAAE;QAAb,CAAa,EAAE,CAAC,CAAC;MACzD;IACF;EACF,CAAC;EAKD/C,SAAA,CAAAY,SAAA,CAAAY,kBAAkB,GAAlB,UAAmBQ,EAAoC;IAAvD,IAAAS,KAAA;IACE,IAAIT,EAAE,KAAK,IAAI,CAACtB,eAAe,EAAE;IAEjC,IAAI,IAAI,CAACsC,UAAU,EAAE;MACnB,IAAI,CAAC5C,SAAS,CAAC6C,MAAM,CAAC,IAAI,CAACD,UAAU,CAAC;IACxC;IAEC,IAAY,CAACtC,eAAe,GAAGsB,EAAE;IAElC,IAAIA,EAAE,EAAE;MACNA,EAAE,CAAC,WAAW,CAAC,GAAG,IAAI;MACtB,IAAI,CAAC5B,SAAS,CAAC8C,GAAG,CACf,IAAI,CAACF,UAAU,GAAG;QACjB,IAAMlB,IAAI,GAAGW,KAAI,CAACd,OAAO,EAAE;QAC3B,IAAIG,IAAI,CAACqB,yBAAyB,EAAE;UAClC;UACA;UACA;UACA;UACA;UACAnB,EAAE,CAAC,SAAS,CAAC,EAAE;QACjB,CAAC,MAAM;UACL;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACApD,mBAAmB,CAACoD,EAAE,CAAC;QACzB;MACF,CAAE,CACH;IACH,CAAC,MAAM;MACL,OAAO,IAAI,CAACgB,UAAU;IACxB;EACF,CAAC;EAEDhD,SAAA,CAAAY,SAAA,CAAAmC,MAAM,GAAN;IAAA,IAAAN,KAAA;IACE5C,mBAAmB,CAAC,IAAI,CAAC;IAEzB,IAAI,IAAI,CAACuD,YAAY,EAAE,EAAE;MACvB,IAAI,CAAChD,SAAS,CAACiD,OAAO,CAAC,UAACC,QAAQ;QAAK,OAAAA,QAAQ,CAACb,KAAI,CAAC;MAAd,CAAc,CAAC;IACtD;IAEA,IAAI,CAAChC,KAAK,GAAG,KAAK;EACpB,CAAC;EAEOT,SAAA,CAAAY,SAAA,CAAAwC,YAAY,GAApB;IACE,IAAI,CAAC,IAAI,CAAC3C,KAAK,IAAI,CAAC,IAAI,CAACL,SAAS,CAACmD,IAAI,EAAE;MACvC,OAAO,KAAK;IACd;IAEA,IAAItE,wBAAwB,CAAC,IAAI,CAAC8B,aAAa,CAAC,IAAI,IAAI,CAACL,eAAe,EAAE;MAChE,IAAAuB,WAAW,GAAK,IAAI,CAACvB,eAAe,CAACkB,OAAO,CAAAK,WAAjC;MACnB,IAAIA,WAAW,KAAK,YAAY,IAAIA,WAAW,KAAK,mBAAmB,EAAE;QACvE,OAAO,KAAK;MACd;IACF;IAEA,OAAO,IAAI;EACb,CAAC;EAEMjC,SAAA,CAAAY,SAAA,CAAA4C,IAAI,GAAX;IACE,IAAI,CAAC,IAAI,CAAChD,OAAO,EAAE;MACjB,IAAI,CAACA,OAAO,GAAG,IAAI;MAEnB;MACA,IAAI,CAACiB,KAAK,EAAE;MAEZ,IAAI,CAACgC,MAAM,EAAE;MACb;MACA;MACA,IAAI,CAACA,MAAM,GAAGzD,SAAS,CAACY,SAAS,CAAC6C,MAAM;MAExC,IAAMzB,EAAE,GAAG,IAAI,CAACtB,eAAe;MAC/B,IAAIsB,EAAE,EAAEA,EAAE,CAAC0B,WAAW,EAAE;IAC1B;EACF,CAAC;EAED;EACA;EACQ1D,SAAA,CAAAY,SAAA,CAAA6C,MAAM,GAAd,aAAkB,CAAC;EAIXzD,SAAA,CAAAY,SAAA,CAAAmB,WAAW,GAAnB,UAAoBd,SAA0B;IAA9C,IAAAwB,KAAA;IAAoB,IAAAxB,SAAA;MAAAA,SAAA,GAAY,IAAI,CAACA,SAAS;IAAA;IAC5C,IAAMe,EAAE,GAAG,IAAI,CAACtB,eAAe;IAC/B,IAAIsB,EAAE,IAAIA,EAAE,CAACJ,OAAO,CAACK,WAAW,KAAK,UAAU,EAAE;MAC/C;IACF;IAEA,IAAM0B,YAAY,GAAAC,QAAA,CAAAA,QAAA,KAIb,IAAI,CAAC/B,cAAc,CAACZ,SAAS,CAAC;MACjC4C,OAAO,EAAE,IAAI;MACbC,QAAQ,EAAE,SAAAA,CAAChC,IAAI;QAAK,OAAAW,KAAI,CAACD,OAAO,CAACV,IAAI,CAAC;MAAlB;IAAkB,EACvC;IAED,IAAI,CAAC,IAAI,CAACiC,SAAS,IAAI,CAACtF,KAAK,CAACkF,YAAY,EAAE,IAAI,CAACI,SAAS,CAAC,EAAE;MAC3D,IAAI,CAACN,MAAM,EAAE;MACb,IAAI,CAACA,MAAM,GAAG,IAAI,CAACnE,KAAK,CAAC0E,KAAK,CAAE,IAAI,CAACD,SAAS,GAAGJ,YAAa,CAAC;IACjE;EACF,CAAC;EAQM3D,SAAA,CAAAY,SAAA,CAAAqD,cAAc,GAArB;IACE,IAAI,CAACC,SAAS,GAAG,KAAK,CAAC;EACzB,CAAC;EAEOlE,SAAA,CAAAY,SAAA,CAAAuD,WAAW,GAAnB,UACEvB,MAAwB,EACxB3B,SAAyC;IAEjC,IAAAiD,SAAS,GAAK,IAAI,CAAAA,SAAT;IACjB,OAAO,EACLA,SAAS;IACT;IACA;IACA;IACAA,SAAS,CAACE,OAAO,KAAKlF,uBAAuB,CAACQ,GAAG,CAAC,IAAI,CAACJ,KAAK,CAAC,IAC7Db,KAAK,CAACwC,SAAS,EAAEiD,SAAS,CAACjD,SAAS,CAAC,IACrCxC,KAAK,CAACmE,MAAM,CAACyB,IAAI,EAAEH,SAAS,CAACtB,MAAM,CAACyB,IAAI,CAAC,CAC1C;EACH,CAAC;EAEMrE,SAAA,CAAAY,SAAA,CAAA0D,UAAU,GAAjB,UACE1B,MAAsB,EACtBtC,QAAsB,EACtBsB,OAGC,EACD2C,kBAAsC;IAPxC,IAAA9B,KAAA;IASE,IAAM+B,MAAM,GAAG,IAAI9F,UAAU,EAAE;IAC/B,IAAM6C,aAAa,GACjB1C,eAAe,CAAC+D,MAAM,CAAC6B,MAAM,CAAC,GAAG7B,MAAM,CAAC6B,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,GAAG,EAAE;IAE9D;IACA;IACA,IAAI,CAACjD,KAAK,EAAE;IAEZ,IAAI,aAAa,IAAImB,MAAM,IAAI/D,eAAe,CAAC+D,MAAM,CAAC+B,WAAW,CAAC,EAAE;MAClE,IAAMC,UAAU,GAAGjG,oBAAoB,CAAC,IAAI,CAACgD,OAAO,EAAE,CAACiB,MAAM,EAAEA,MAAM,CAAC;MACtEA,MAAM,CAACyB,IAAI,GAAGO,UAAU;MAExB;MACA;MACA;MACA;MACA;IACF,CAAC,MAAM,IAAI,SAAS,IAAIhC,MAAM,IAAIA,MAAM,CAACiC,OAAO,EAAE;MAChD,IAAM/C,IAAI,GAAG,IAAI,CAACH,OAAO,EAAE;MAC3BiB,MAAM,CAACyB,IAAI,GAAGG,MAAM,CAACM,KAAK,CAAChD,IAAI,CAACc,MAAM,EAAEA,MAAM,CAACyB,IAAI,CAAC;IACtD;IAEA,IAAI,CAAC9C,aAAa,GAAGA,aAAa;IAElC,IAAIK,OAAO,CAACK,WAAW,KAAK,UAAU,EAAE;MACtC,IAAI,CAACE,cAAc,CACjB;QAAES,MAAM,EAAEA,MAAM,CAACyB,IAAI;QAAEnC,QAAQ,EAAE;MAAI,CAAE,EACvC,IAAI,CAACL,cAAc,CAACD,OAAO,CAACX,SAAS,CAAC,CACvC;IACH,CAAC,MAAM,IAAIsD,kBAAkB,wCAAgC;MAC3D,IAAIQ,iBAAiB,CAACnC,MAAM,EAAEhB,OAAO,CAACoD,WAAW,CAAC,EAAE;QAClD;QACA;QACA;QACA;QACA,IAAI,CAAC1F,KAAK,CAAC2F,kBAAkB,CAAC,UAAC3F,KAAK;UAClC,IAAImD,KAAI,CAAC0B,WAAW,CAACvB,MAAM,EAAEhB,OAAO,CAACX,SAAS,CAAC,EAAE;YAC/C3B,KAAK,CAAC4F,UAAU,CAAC;cACfpE,KAAK,EAAER,QAAQ;cACf+D,IAAI,EAAEzB,MAAM,CAACyB,IAAS;cACtBpD,SAAS,EAAEW,OAAO,CAACX,SAAS;cAC5BkE,SAAS,EAAEZ,kBAAkB;aAC9B,CAAC;YAEF9B,KAAI,CAACyB,SAAS,GAAG;cACftB,MAAM,EAAAA,MAAA;cACN3B,SAAS,EAAEW,OAAO,CAACX,SAAS;cAC5BmD,OAAO,EAAElF,uBAAuB,CAACQ,GAAG,CAAC+C,KAAI,CAACnD,KAAK;aAChD;UACH,CAAC,MAAM;YACL;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,IAAImD,KAAI,CAACtB,QAAQ,IAAIsB,KAAI,CAACtB,QAAQ,CAACW,IAAI,CAACI,QAAQ,EAAE;cAChD;cACA;cACAU,MAAM,CAACyB,IAAI,GAAG5B,KAAI,CAACtB,QAAQ,CAACW,IAAI,CAACc,MAAM;cACvC;YACF;YACA;YACA;UACF;UAEA,IAAMwC,WAAW,GAAG3C,KAAI,CAACZ,cAAc,CAACD,OAAO,CAACX,SAAS,CAAC;UAC1D,IAAMa,IAAI,GAAGxC,KAAK,CAACwC,IAAI,CAAIsD,WAAW,CAAC;UAEvC;UACA;UACA;UACA;UACA;UACA;UACA,IAAI,CAAC3C,KAAI,CAACjC,OAAO,IAAI/B,KAAK,CAACgE,KAAI,CAACxB,SAAS,EAAEW,OAAO,CAACX,SAAS,CAAC,EAAE;YAC7D;YACA;YACAwB,KAAI,CAACV,WAAW,CAACH,OAAO,CAACX,SAAS,CAAC;UACrC;UAEA;UACA;UACA;UACA;UACA;UACAwB,KAAI,CAACN,cAAc,CAACL,IAAI,EAAEsD,WAAW,CAAC;UACtC,IAAItD,IAAI,CAACI,QAAQ,EAAE;YACjBU,MAAM,CAACyB,IAAI,GAAGvC,IAAI,CAACc,MAAM;UAC3B;QACF,CAAC,CAAC;MACJ,CAAC,MAAM;QACL,IAAI,CAACsB,SAAS,GAAG,KAAK,CAAC;MACzB;IACF;EACF,CAAC;EAEMlE,SAAA,CAAAY,SAAA,CAAAyE,SAAS,GAAhB;IACE,IAAI,CAAC/D,YAAY,GAAG,IAAI;IACxB,OAAQ,IAAI,CAACP,aAAa,GAAG/B,aAAa,CAACsG,KAAK;EAClD,CAAC;EAEMtF,SAAA,CAAAY,SAAA,CAAA2E,SAAS,GAAhB,UAAiBC,KAAkB;IACjC,IAAI,CAACzE,aAAa,GAAG/B,aAAa,CAACwG,KAAK;IACxC,IAAI,CAACtB,SAAS,GAAG,KAAK,CAAC;IAEvB,IAAI,CAACzC,KAAK,EAAE;IAEZ,IAAI+D,KAAK,CAACjE,aAAa,EAAE;MACvB,IAAI,CAACA,aAAa,GAAGiE,KAAK,CAACjE,aAAa;IAC1C;IAEA,IAAIiE,KAAK,CAAClE,YAAY,EAAE;MACtB,IAAI,CAACA,YAAY,GAAGkE,KAAK,CAAClE,YAAY;IACxC;IAEA,OAAOkE,KAAK;EACd,CAAC;EACH,OAAAxF,SAAC;AAAD,CAAC,CAjcD;;AAmcA,OAAM,SAAU+E,iBAAiBA,CAC/BnC,MAAsB,EACtBoC,WAAiC;EAAjC,IAAAA,WAAA;IAAAA,WAAA,SAAiC;EAAA;EAEjC,IAAMS,YAAY,GAAGT,WAAW,KAAK,QAAQ,IAAIA,WAAW,KAAK,KAAK;EACtE,IAAIU,eAAe,GAAG,CAAC5G,qBAAqB,CAAC8D,MAAM,CAAC;EACpD,IAAI,CAAC8C,eAAe,IAAID,YAAY,IAAI7C,MAAM,CAACyB,IAAI,EAAE;IACnDqB,eAAe,GAAG,IAAI;EACxB;EACA,OAAOA,eAAe;AACxB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}